# Khmer Sentiment Analysis - Professional ML Project

A production-ready sentiment analysis system for Khmer text using traditional machine learning and deep learning approaches.

## ğŸ¯ Project Overview

This project implements a comprehensive sentiment analysis pipeline for Khmer language text, addressing unique challenges such as Unicode normalization, informal writing styles, and limited NLP resources. The system trains and compares multiple models to achieve optimal performance.

## ğŸ“ Professional Folder Structure

```
PROJECT/
â”‚
â”œâ”€â”€ data/                           # Dataset storage
â”‚   â”œâ”€â”€ Data Collection - Sheet1.csv
â”‚   â””â”€â”€ data_cleaned_all.csv
â”‚
â”œâ”€â”€ src/                            # Source code modules
â”‚   â”œâ”€â”€ __init__.py                 # Package initializer
â”‚   â”œâ”€â”€ config.py                   # Configuration & hyperparameters
â”‚   â”œâ”€â”€ preprocessing.py            # Text preprocessing (Khmer-specific)
â”‚   â”œâ”€â”€ data_loader.py              # Data loading & preparation
â”‚   â”œâ”€â”€ feature_extraction.py      # TF-IDF & feature engineering
â”‚   â”œâ”€â”€ models.py                   # Traditional ML models
â”‚   â”œâ”€â”€ deep_learning.py            # LSTM/BiLSTM models
â”‚   â”œâ”€â”€ evaluation.py               # Model evaluation & visualization
â”‚   â”œâ”€â”€ model_persistence.py        # Model saving/loading
â”‚   â””â”€â”€ threshold_optimization.py   # ğŸ†• ROC & threshold optimization
â”‚
â”œâ”€â”€ models/                         # Saved model artifacts
â”‚   â””â”€â”€ saved_models/
â”‚       â”œâ”€â”€ best_model_*.pkl            # Trained models
â”‚       â”œâ”€â”€ best_model_metadata_*.json
â”‚       â”œâ”€â”€ tokenizer_*.pkl             # Preprocessing objects
â”‚       â””â”€â”€ optimal_thresholds_*.json   # ğŸ†• Optimal decision thresholds
â”‚
â”œâ”€â”€ results/                        # Analysis outputs
â”‚   â”œâ”€â”€ figures/                        # Visualizations
â”‚   â”‚   â”œâ”€â”€ roc_curves_*.png            # ğŸ†• ROC curve plots
â”‚   â”‚   â””â”€â”€ threshold_analysis_*.png    # ğŸ†• Threshold optimization
â”‚   â””â”€â”€ reports/                        # Performance reports
â”‚       â”œâ”€â”€ model_comparison_*.csv
â”‚       â””â”€â”€ threshold_report_*.csv      # ğŸ†• Threshold recommendations
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks
â”‚   â”œâ”€â”€ Model.ipynb                 # Original analysis notebook
â”‚   â””â”€â”€ Notebook.ipynb              # Exploratory analysis
â”‚
â”œâ”€â”€ tests/                          # Unit tests (optional)
â”‚
â”œâ”€â”€ train.py                        # Main training script
â”œâ”€â”€ predict.py                      # Prediction script
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ PROJECT_STRUCTURE.md            # Detailed documentation
â””â”€â”€ README.md                       # This file
```

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd PROJECT

# Install dependencies
pip install -r requirements.txt
```

### Training Models

```bash
# Train all models (including LSTM)
python train.py

# Train without LSTM
python train.py --no_lstm

# Train with custom data path
python train.py --data_path path/to/your/data.csv
```

### Making Predictions

```bash
# Single text prediction
python predict.py --model_path models/saved_models/best_model_*.pkl --text "á¢áŸáŸ’á…á¶ášáŸ’á™áá¶áŸáŸ‹!"

# Batch prediction from CSV
python predict.py --model_path models/saved_models/best_model_*.pkl \
                  --input_file data/new_texts.csv \
                  --output_file results/predictions.csv

# ğŸ†• Prediction with optimal thresholds (improved accuracy)
python predict.py --model_path models/saved_models/best_model_*.pkl \
                  --thresholds_path models/saved_models/optimal_thresholds_*.json \
                  --threshold_method f1 \
                  --input_file data/new_texts.csv \
                  --output_file results/predictions_optimized.csv \
                  --return_proba
```

## ğŸ› ï¸ Module Documentation

### src/preprocessing.py
- **`preprocess_khmer(text)`**: Khmer-specific text preprocessing
  - Unicode normalization (NFC)
  - Slang handling
  - URL and emoji removal
  - Character normalization

### src/data_loader.py
- **`load_data(file_path)`**: Load dataset from CSV
- **`clean_data(df)`**: Remove invalid entries
- **`prepare_train_test_split()`**: Stratified train-test split

### src/feature_extraction.py
- **`create_tfidf_vectorizer()`**: Configure TF-IDF
- **`compute_class_weights()`**: Handle class imbalance

### src/models.py
- **Pipeline creation** for 5 ML models:
  - Logistic Regression
  - Support Vector Machine (LinearSVC)
  - Naive Bayes (MultinomialNB)
  - Random Forest
  - XGBoost (optional)
- **`train_model_with_search()`**: RandomizedSearchCV training

### src/deep_learning.py
- **`create_lstm_model()`**: Bidirectional LSTM architecture
- **`prepare_sequences()`**: Tokenization & padding
- **`train_lstm_model()`**: Training with early stopping

### src/evaluation.py
- **`evaluate_model()`**: Comprehensive metrics
- **`compare_models()`**: Multi-model comparison
- **`plot_confusion_matrix()`**: Visualization
- **`analyze_errors()`**: Misclassification analysis

### src/model_persistence.py
- **`save_model()`**: Save model with metadata
- **`load_model()`**: Load trained model
- **`save_comparison_report()`**: Export results to CSV

### src/threshold_optimization.py ğŸ†•
- **`compute_roc_curves_multiclass()`**: ROC curve analysis
- **`get_optimal_thresholds_multiclass()`**: Find optimal thresholds
- **`predict_with_threshold()`**: Predictions with custom thresholds
- **`plot_roc_curves_multiclass()`**: Visualize ROC curves
- **`plot_threshold_analysis()`**: Threshold vs metrics plots
- **`generate_threshold_report()`**: Comprehensive threshold report

### src/config.py
- Centralized configuration
- All hyperparameters in one place
- Easy to modify settings

## ğŸ“Š Models & Performance

| Model | Type | F1-Macro | Accuracy |
|-------|------|----------|----------|
| Logistic Regression | Traditional ML | - | - |
| SVM | Traditional ML | - | - |
| Naive Bayes | Traditional ML | - | - |
| Random Forest | Traditional ML | - | - |
| XGBoost | Gradient Boosting | - | - |
| BiLSTM | Deep Learning | - | - |

*Run `python train.py` to get updated results*

## ğŸ”§ Configuration

Edit `src/config.py` to customize:
- Data paths
- Hyperparameters
- Feature extraction settings
- Model training parameters

```python
# Example configuration
TFIDF_MAX_FEATURES = 5000
LSTM_UNITS = 64
CV_FOLDS = 3
```

## ğŸ“ˆ Usage Examples

### Training with Custom Settings

```python
from src.config import *
from src.data_loader import load_data, prepare_train_test_split
from src.models import create_logistic_regression_pipeline

# Load data
df = load_data(CLEANED_DATA_PATH)

# Prepare data
X_train, X_test, y_train, y_test = prepare_train_test_split(df)

# Train model
from src.feature_extraction import create_tfidf_vectorizer
tfidf = create_tfidf_vectorizer()
pipeline = create_logistic_regression_pipeline(tfidf, class_weight)
```

### Loading and Using Saved Models

```python
from src.model_persistence import load_model
from src.preprocessing import preprocess_khmer

# Load model
model = load_model('models/saved_models/best_model_logistic_regression_*.pkl')

# Predict
text = "á¢áŸáŸ’á…á¶ášáŸ’á™áá¶áŸáŸ‹!"
cleaned = preprocess_khmer(text)
prediction = model.predict([cleaned])
print(f"Sentiment: {prediction[0]}")
```OC Analysis & Threshold Optimization**: ğŸ†• Find optimal decision boundaries
6. **Reproducible**: Fixed random seeds, version control
7. **Production-Ready**: Command-line scripts for deployment
8. **Comprehensive Evaluation**: Multiple metrics + visualizations
9. **Easy Configuration**: Centralized settings
10. **Optimal Thresholds**: ğŸ†• Improve accuracy with custom thresholds

## ğŸ†• ROC & Threshold Optimization

The training pipeline now includes **automatic threshold optimization** to improve classification performance:

- **ROC Curves**: Visualize model performance across all classes
- **Optimal Thresholds**: Find best decision boundaries using:
  - **F1 Score Maximization** (recommended for balanced tasks)
  - **Youden's J Statistic** (maximum class separation)
- **Threshold Analysis**: Precision, Recall, F1 vs. Threshold plots
- **Custom Predictions**: Use optimized thresholds for better results

**Expected Improvement**: 2-8% increase in F1 score

See [ROC & Threshold Guide](docs/ROC_THRESHOLD_GUIDE.md) for details.
1. **Modular Architecture**: Clean separation of concerns
2. **Khmer-Specific Preprocessing**: Handles Unicode and slang
3. **Multiple Models**: Compare 6 different approaches
4. **Automated Model Selection**: Best model based on F1-Macro
5. **Reproducible**: Fixed random seeds, version control
6. **Production-Ready**: Command-line scripts for deployment
7. **Comprehensive Evaluation**: Multiple metrics + visualizations
8. **Easy Configuration**: Centralized settings

## ğŸ“ Citation

If you use this project, please cite:

```
Khmer Sentiment Analysis System
Version: 1.0
Date: December 2025
```

## ğŸ¤ Contributing

1. Follow the modular structure
2. Add docstrings to all functions
3. Update configuration in `config.py`
4. Add tests for new features

## ğŸ“„ License

[Add your license here]

## ğŸ“§ Contact

[Add your contact information]

---

**Built with** ğŸ§¡ **for the Khmer NLP community**
